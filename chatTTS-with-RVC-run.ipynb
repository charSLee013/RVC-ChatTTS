{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 脚本介绍\n",
    "将chatTTS的语音通过RVC进行换声\n",
    "并且将中间特征和换声后的Mel频谱图保存下来\n",
    "以便用于训练音色固定的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 前置依赖\n",
    "import random\n",
    "import wave\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import ChatTTS\n",
    "from scipy.io.wavfile import write\n",
    "import librosa\n",
    "\n",
    "# from zh_normalization import TextNormalizer\n",
    "import logging\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载chaTTS模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('mirror013/ChatTTS')\n",
    "\n",
    "# 加载模型\n",
    "chat = ChatTTS.Chat()\n",
    "chat.load_models(\n",
    "    source=\"local\",\n",
    "    local_path=model_dir,\n",
    "    device='cpu',\n",
    "    compile=False,\n",
    ")\n",
    "\n",
    "SEED = 1397\n",
    "torch.manual_seed(SEED) # 音色种子\n",
    "# load from local file if exists\n",
    "if os.path.exists('spk_emb.npy'):\n",
    "    spk_emb = torch.load('spk_emb.npy',map_location='cpu')\n",
    "else:\n",
    "    spk_emb = chat.sample_random_speaker()\n",
    "\n",
    "params_infer_code = {\n",
    "    'spk_emb': spk_emb,\n",
    "    'temperature': 0.1,\n",
    "    'top_P': 0.7,\n",
    "    'top_K': 20,\n",
    "}\n",
    "\n",
    "params_refine_text = {'prompt': '[oral_0][laugh_0][break_0]'}\n",
    "\n",
    "text = \"接下来,杨叔，借我看一下现场地图。他肯定穿过了前面的那扇门，不可能在这么小的地方晃悠了两小时。\" # 该文本仅作测试用途"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RVC 依赖函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from fairseq import checkpoint_utils\n",
    "import torchaudio\n",
    "from lib.audio import load_audio\n",
    "from lib.infer_pack.models import (\n",
    "    SynthesizerTrnMs256NSFsid,\n",
    "    SynthesizerTrnMs256NSFsid_nono,\n",
    "    SynthesizerTrnMs768NSFsid,\n",
    "    SynthesizerTrnMs768NSFsid_nono,\n",
    ")\n",
    "from vc_infer_pipeline import VC\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import torch\n",
    "\n",
    "now_dir = os.getcwd()\n",
    "sys.path.append(now_dir)\n",
    "\n",
    "using_cli = False\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "is_half = False\n",
    "\n",
    "    \n",
    "if device == 'mps':\n",
    "    # 设置环境变量 PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# 只在jupyter notebook中运行\n",
    "from IPython import get_ipython\n",
    "if get_ipython() is not None:\n",
    "    %set_env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "    pass\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, device, is_half):\n",
    "        self.device = device\n",
    "        self.is_half = is_half\n",
    "        self.n_cpu = 0\n",
    "        self.gpu_name = None\n",
    "        self.gpu_mem = None\n",
    "        self.x_pad, self.x_query, self.x_center, self.x_max = self.device_config()\n",
    "\n",
    "    def device_config(self) -> tuple:\n",
    "        if torch.cuda.is_available() and device != \"cpu\":\n",
    "            i_device = int(self.device.split(\":\")[-1])\n",
    "            self.gpu_name = torch.cuda.get_device_name(i_device)\n",
    "            if (\n",
    "                (\"16\" in self.gpu_name and \"V100\" not in self.gpu_name.upper())\n",
    "                or \"P40\" in self.gpu_name.upper()\n",
    "                or \"1060\" in self.gpu_name\n",
    "                or \"1070\" in self.gpu_name\n",
    "                or \"1080\" in self.gpu_name\n",
    "            ):\n",
    "                print(\"16系/10系显卡和P40强制单精度\")\n",
    "                self.is_half = False\n",
    "                for config_file in [\"32k.json\", \"40k.json\", \"48k.json\"]:\n",
    "                    with open(f\"configs/{config_file}\", \"r\") as f:\n",
    "                        strr = f.read().replace(\"true\", \"false\")\n",
    "                    with open(f\"configs/{config_file}\", \"w\") as f:\n",
    "                        f.write(strr)\n",
    "                with open(\"trainset_preprocess_pipeline_print.py\", \"r\") as f:\n",
    "                    strr = f.read().replace(\"3.7\", \"3.0\")\n",
    "                with open(\"trainset_preprocess_pipeline_print.py\", \"w\") as f:\n",
    "                    f.write(strr)\n",
    "            else:\n",
    "                self.gpu_name = None\n",
    "            self.gpu_mem = int(\n",
    "                torch.cuda.get_device_properties(i_device).total_memory\n",
    "                / 1024\n",
    "                / 1024\n",
    "                / 1024\n",
    "                + 0.4\n",
    "            )\n",
    "            if self.gpu_mem <= 4:\n",
    "                with open(\"trainset_preprocess_pipeline_print.py\", \"r\") as f:\n",
    "                    strr = f.read().replace(\"3.7\", \"3.0\")\n",
    "                with open(\"trainset_preprocess_pipeline_print.py\", \"w\") as f:\n",
    "                    f.write(strr)\n",
    "        elif torch.backends.mps.is_available():\n",
    "            print(\"没有发现支持的N卡, 使用MPS进行推理\")\n",
    "            self.device = \"mps\"\n",
    "        else:\n",
    "            print(\"没有发现支持的N卡, 使用CPU进行推理\")\n",
    "            self.device = \"cpu\"\n",
    "            self.is_half = False\n",
    "\n",
    "        if self.n_cpu == 0:\n",
    "            self.n_cpu = cpu_count()\n",
    "\n",
    "        if self.is_half:\n",
    "            # 6G显存配置\n",
    "            x_pad = 3\n",
    "            x_query = 10\n",
    "            x_center = 60\n",
    "            x_max = 65\n",
    "        else:\n",
    "            # 5G显存配置\n",
    "            x_pad = 1\n",
    "            x_query = 6\n",
    "            x_center = 38\n",
    "            x_max = 41\n",
    "\n",
    "        if self.gpu_mem != None and self.gpu_mem <= 4:\n",
    "            x_pad = 1\n",
    "            x_query = 5\n",
    "            x_center = 30\n",
    "            x_max = 32\n",
    "\n",
    "        return x_pad, x_query, x_center, x_max\n",
    "\n",
    "\n",
    "config = Config(device, is_half)\n",
    "now_dir = os.getcwd()\n",
    "sys.path.append(now_dir)\n",
    "\n",
    "hubert_model = None\n",
    "\n",
    "\n",
    "def load_hubert():\n",
    "    global hubert_model\n",
    "    models, _, _ = checkpoint_utils.load_model_ensemble_and_task(\n",
    "        [\"hubert_base.pt\"],\n",
    "        suffix=\"\",\n",
    "    )\n",
    "    hubert_model = models[0]\n",
    "    hubert_model = hubert_model.to(config.device)\n",
    "    if config.is_half:\n",
    "        hubert_model = hubert_model.half()\n",
    "    else:\n",
    "        hubert_model = hubert_model.float()\n",
    "    hubert_model.eval()\n",
    "\n",
    "last_model_path = None\n",
    "def vc_single(\n",
    "    sid=0,\n",
    "    audio=None, # 需要确保是16000采样率\n",
    "    f0_up_key=0,\n",
    "    f0_file=None,\n",
    "    f0_method=\"rmvpe\",\n",
    "    file_index=\"\",  # .index file\n",
    "    file_index2=\"\",\n",
    "    # file_big_npy,\n",
    "    index_rate=1.0,\n",
    "    filter_radius=3,\n",
    "    resample_sr=0,\n",
    "    rms_mix_rate=0,\n",
    "    model_path=\"\",\n",
    "    output_path=\"\",\n",
    "    protect=0.33,\n",
    "):\n",
    "    \n",
    "    global tgt_sr, net_g, vc, hubert_model, version, last_model_path\n",
    "    if last_model_path != model_path:\n",
    "        last_model_path = get_vc(model_path)\n",
    "    if audio is None:\n",
    "        raise \"You need to upload an audio file\"\n",
    "    if not isinstance(audio,np.ndarray):\n",
    "        raise \"Make sure audio is a numpy array\"\n",
    "\n",
    "    f0_up_key = int(f0_up_key)\n",
    "    audio_max = np.abs(audio).max() / 0.95\n",
    "\n",
    "    if audio_max > 1:\n",
    "        audio /= audio_max\n",
    "    times = [0, 0, 0]\n",
    "\n",
    "    if hubert_model == None:\n",
    "        load_hubert()\n",
    "\n",
    "    if_f0 = cpt.get(\"f0\", 1)\n",
    "\n",
    "    file_index = (\n",
    "        (\n",
    "            file_index.strip(\" \")\n",
    "            .strip('\"')\n",
    "            .strip(\"\\n\")\n",
    "            .strip('\"')\n",
    "            .strip(\" \")\n",
    "            .replace(\"trained\", \"added\")\n",
    "        )\n",
    "        if file_index != \"\"\n",
    "        else file_index2\n",
    "    )\n",
    "\n",
    "    audio_opt = vc.pipeline(\n",
    "        hubert_model,\n",
    "        net_g,\n",
    "        sid,\n",
    "        audio,\n",
    "        \"\",\n",
    "        times,\n",
    "        f0_up_key,\n",
    "        f0_method,\n",
    "        file_index,\n",
    "        # file_big_npy,\n",
    "        index_rate,\n",
    "        if_f0,\n",
    "        filter_radius,\n",
    "        tgt_sr,\n",
    "        resample_sr,\n",
    "        rms_mix_rate,\n",
    "        version,\n",
    "        f0_file=f0_file,\n",
    "        protect=protect,\n",
    "        ret_audio_opt=True,\n",
    "    )\n",
    "    return audio_opt\n",
    "\n",
    "\n",
    "def get_vc(model_path):\n",
    "    global n_spk, tgt_sr, net_g, vc, cpt, device, is_half, version\n",
    "    # print(\"loading pth %s\" % model_path)\n",
    "    cpt = torch.load(model_path, map_location=\"cpu\")\n",
    "    tgt_sr = cpt[\"config\"][-1]\n",
    "    cpt[\"config\"][-3] = cpt[\"weight\"][\"emb_g.weight\"].shape[0]  # n_spk\n",
    "    if_f0 = cpt.get(\"f0\", 1)\n",
    "    version = cpt.get(\"version\", \"v1\")\n",
    "    if version == \"v1\":\n",
    "        if if_f0 == 1:\n",
    "            net_g = SynthesizerTrnMs256NSFsid(*cpt[\"config\"], is_half=is_half)\n",
    "        else:\n",
    "            net_g = SynthesizerTrnMs256NSFsid_nono(*cpt[\"config\"])\n",
    "    elif version == \"v2\":\n",
    "        if if_f0 == 1:\n",
    "            net_g = SynthesizerTrnMs768NSFsid(*cpt[\"config\"], is_half=is_half)\n",
    "        else:\n",
    "            net_g = SynthesizerTrnMs768NSFsid_nono(*cpt[\"config\"])\n",
    "    del net_g.enc_q\n",
    "    print(net_g.load_state_dict(cpt[\"weight\"], strict=False))\n",
    "    net_g.eval().to(device)\n",
    "    if is_half:\n",
    "        net_g = net_g.half()\n",
    "    else:\n",
    "        net_g = net_g.float()\n",
    "    vc = VC(tgt_sr, config)\n",
    "    n_spk = cpt[\"config\"][-3]\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义RVC一些参数\n",
    "f0_up_key = 0\n",
    "model_path = \"weights/three_moon_e20_s10000.pth\"\n",
    "file_index = ''\n",
    "f0_method = 'rmvpe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将音频信号转化回Mel频谱图\n",
    "mel_spec = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=24000,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=100,\n",
    "    center=True,\n",
    "    power=1,\n",
    ")\n",
    "\n",
    "def safe_log(x: torch.Tensor, clip_val: float = 1e-7) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the element-wise logarithm of the input tensor with clipping to avoid near-zero values.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor.\n",
    "        clip_val (float, optional): Minimum value to clip the input tensor. Defaults to 1e-7.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Element-wise logarithm of the input tensor with clipping applied.\n",
    "    \"\"\"\n",
    "    return torch.log(torch.clip(x, min=clip_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def synthesize_and_process_audio(text):\n",
    "    \"\"\"\n",
    "    整合函数，用于生成文本对应的语音，通过RVC换声，并将结果转换为梅尔频谱图。\n",
    "    \n",
    "    参数:\n",
    "    - text: 输入文本字符串\n",
    "    \n",
    "    返回:\n",
    "    - hidden: ChatTTS生成的隐藏特征\n",
    "    - log_mel_spec: 经过RVC处理的音频的梅尔频谱图\n",
    "    \"\"\"\n",
    "    # 使用ChatTTS生成语音\n",
    "    torch.manual_seed(SEED)\n",
    "    chat_result = chat.infer_debug(text=text, params_infer_code=params_infer_code)\n",
    "    audio_numpy = chat_result['wav'][0]\n",
    "    hidden = chat_result['hiddens'][0]\n",
    "    \n",
    "    # 重采样至16kHz\n",
    "    resample_audio = librosa.resample(audio_numpy, orig_sr=24000, target_sr=16000)[0]\n",
    "    \n",
    "    # 通过RVC换声\n",
    "    audio_opt = vc_single(\n",
    "        sid=0,\n",
    "        audio=resample_audio,\n",
    "        f0_up_key=f0_up_key,\n",
    "        f0_method=f0_method,\n",
    "        file_index=file_index,\n",
    "        filter_radius=3,\n",
    "        resample_sr=24000,\n",
    "        rms_mix_rate=1,\n",
    "        model_path=model_path,\n",
    "        protect=0.33,\n",
    "    )\n",
    "    \n",
    "    # 将转换后的音频转换为梅尔频谱图\n",
    "    log_mel_spec = safe_log(mel_spec(torch.from_numpy(audio_opt)))\n",
    "    \n",
    "    return hidden, log_mel_spec.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_md5(text):\n",
    "    \"\"\"计算文本的MD5\"\"\"\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "def save_data(hidden, log_mel_spec, md5):\n",
    "    \"\"\"保存数据到指定目录\"\"\"\n",
    "    save_folder = \"train_rvc\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    filename = os.path.join(save_folder, f\"{md5}.npz\")\n",
    "    if not os.path.exists(filename):\n",
    "        np.savez(filename, hidden=hidden, log_mel_spec=log_mel_spec)\n",
    "\n",
    "def process_texts_from_file(file_path):\n",
    "    \"\"\"从文件中读取文本，处理并保存数据\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    for line in tqdm.tqdm(lines, desc=\"Processing texts\", unit=\"line\"):\n",
    "        line = line.strip()  # 移除末尾的空白字符\n",
    "        md5 = compute_md5(line)\n",
    "        save_path = os.path.join(\"train_rvc\", f\"{md5}.npz\")\n",
    "        \n",
    "        # 检查文件是否已存在，如果存在则跳过\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        \n",
    "        hidden, log_mel_spec = synthesize_and_process_audio(line)\n",
    "        save_data(hidden, log_mel_spec, md5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你的文本文件路径是固定的或者作为参数传递\n",
    "file_path = \"all.lab\"\n",
    "process_texts_from_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
